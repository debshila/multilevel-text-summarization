{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:14:36.576330Z",
     "start_time": "2019-02-05T18:14:34.490451Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from string import digits\n",
    "from time import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pickle import dump, load\n",
    "import logging\n",
    "import itertools\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from scipy import stats\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:36:18.852676Z",
     "start_time": "2019-02-05T18:36:16.535468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19000, 7)\n",
      "(15283, 7)\n"
     ]
    }
   ],
   "source": [
    "# Read in json\n",
    "train = pd.read_json('/Users/dbm/Documents/Insight S19/data/cnn_dmail_news_summary_words_train_df.json', orient='records', lines=True)\n",
    "print(train.shape)\n",
    "\n",
    "# Select only those articles with headlines\n",
    "train = train.dropna(subset = ['headline'])\n",
    "print(train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:36:35.415530Z",
     "start_time": "2019-02-05T18:36:35.312639Z"
    }
   },
   "outputs": [],
   "source": [
    "# Randomly sample 50% of the rows\n",
    "df = train.sample(n=650, replace=False, random_state=0)\n",
    "\n",
    "# Remove source name from headlines\n",
    "df['headline'] = df['headline'].apply(lambda x: re.sub(' - CNN.com', '', x) if x is not None else '')\n",
    "df['headline'] = df['headline'].apply(lambda x: re.sub(' | Daily Mail Online', '', x) if x is not None else '')\n",
    "df['story'] = df['story'].apply(lambda x: re.sub('\\(CNN\\) -- ', '', x) if x is not None else '')\n",
    "df.head()\n",
    "# Save small subset of data\n",
    "dump(df, open(\"/Users/dbm/Documents/Insight S19/data/cnn_dailymail_news_summary_650.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create summaries with different return rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:36:39.796861Z",
     "start_time": "2019-02-05T18:36:39.744900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Stories 650\n"
     ]
    }
   ],
   "source": [
    "df = load(\n",
    "    open('/Users/dbm/Documents/Insight S19/data/cnn_dailymail_news_summary_650.pkl', 'rb'))\n",
    "print('Loaded Stories %d' % len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:36:46.929077Z",
     "start_time": "2019-02-05T18:36:46.906169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>headline</th>\n",
       "      <th>publication</th>\n",
       "      <th>story</th>\n",
       "      <th>story_cleaned</th>\n",
       "      <th>summary</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27856235c546051e9eb14c653ac9f0ceef7480a6.story</td>\n",
       "      <td>HowardWebbends25-yearrefereeingcareertotakeupt...</td>\n",
       "      <td>dailymail.com</td>\n",
       "      <td>Howard Webb has blown the final whistle on his...</td>\n",
       "      <td>[howard, webb, blown, final, whistle, year, re...</td>\n",
       "      <td>[Howard Webb retires after 25 years as a refer...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ca790a8018ee64f52a3d21e8931006c38446b4a.story</td>\n",
       "      <td>HousepanelrecommendsHoldercontemptcitation</td>\n",
       "      <td>cnn.com</td>\n",
       "      <td>Washington Voting on strictly partisan lines, ...</td>\n",
       "      <td>[washington, voting, strictly, partisan, line,...</td>\n",
       "      <td>[House leaders say the full chamber could vote...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36f844e62b9e2b2607e059847b32d0e75815231b.story</td>\n",
       "      <td>JustinRosecruisestovictoryinScottishOpentolayd...</td>\n",
       "      <td>dailymail.com</td>\n",
       "      <td>If he navigates the next stretch of uncharted ...</td>\n",
       "      <td>[navigates, next, stretch, uncharted, territor...</td>\n",
       "      <td>[Justin Rose won the Aberdeen Asset Management...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>340dd9818b906ad4c3401c5fb0f37c7251b79166.story</td>\n",
       "      <td>MarceloBrozovictoholdtalkswithArsenaloverpossi...</td>\n",
       "      <td>dailymail.com</td>\n",
       "      <td>The agent of Dinamo Zagreb midfielder Marcelo ...</td>\n",
       "      <td>[agent, dinamo, zagreb, midfielder, marcelo, b...</td>\n",
       "      <td>[Arsenal will hold talks with Marcelon Brozovi...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34b0bb5f8eb3c61ca5a838767072508345398900.story</td>\n",
       "      <td>SarahOuten:Aroundtheworldontwoboatsandabike</td>\n",
       "      <td>cnn.com</td>\n",
       "      <td>Honshu, Japan I am attempting to journey from ...</td>\n",
       "      <td>[honshu, japan, attempting, journey, london, l...</td>\n",
       "      <td>[Sarah Outen is attempting to travel around th...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             file  \\\n",
       "0  27856235c546051e9eb14c653ac9f0ceef7480a6.story   \n",
       "1  5ca790a8018ee64f52a3d21e8931006c38446b4a.story   \n",
       "2  36f844e62b9e2b2607e059847b32d0e75815231b.story   \n",
       "3  340dd9818b906ad4c3401c5fb0f37c7251b79166.story   \n",
       "4  34b0bb5f8eb3c61ca5a838767072508345398900.story   \n",
       "\n",
       "                                            headline    publication  \\\n",
       "0  HowardWebbends25-yearrefereeingcareertotakeupt...  dailymail.com   \n",
       "1         HousepanelrecommendsHoldercontemptcitation        cnn.com   \n",
       "2  JustinRosecruisestovictoryinScottishOpentolayd...  dailymail.com   \n",
       "3  MarceloBrozovictoholdtalkswithArsenaloverpossi...  dailymail.com   \n",
       "4        SarahOuten:Aroundtheworldontwoboatsandabike        cnn.com   \n",
       "\n",
       "                                               story  \\\n",
       "0  Howard Webb has blown the final whistle on his...   \n",
       "1  Washington Voting on strictly partisan lines, ...   \n",
       "2  If he navigates the next stretch of uncharted ...   \n",
       "3  The agent of Dinamo Zagreb midfielder Marcelo ...   \n",
       "4  Honshu, Japan I am attempting to journey from ...   \n",
       "\n",
       "                                       story_cleaned  \\\n",
       "0  [howard, webb, blown, final, whistle, year, re...   \n",
       "1  [washington, voting, strictly, partisan, line,...   \n",
       "2  [navigates, next, stretch, uncharted, territor...   \n",
       "3  [agent, dinamo, zagreb, midfielder, marcelo, b...   \n",
       "4  [honshu, japan, attempting, journey, london, l...   \n",
       "\n",
       "                                             summary  type  \n",
       "0  [Howard Webb retires after 25 years as a refer...  news  \n",
       "1  [House leaders say the full chamber could vote...  news  \n",
       "2  [Justin Rose won the Aberdeen Asset Management...  news  \n",
       "3  [Arsenal will hold talks with Marcelon Brozovi...  news  \n",
       "4  [Sarah Outen is attempting to travel around th...  news  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index()\n",
    "df = df.drop(columns = ['index'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T16:30:18.003313Z",
     "start_time": "2019-02-05T16:30:17.993500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Pakistani teen jailed for blasphemy in school ...\n",
       "1                    Shop with your head, not your heart\n",
       "2      Kidney patients left freezing on Kent and Cant...\n",
       "3                     Fired chef gets revenge on Twitter\n",
       "4      Syria crisis: 'I didn't join Navy to fight for...\n",
       "5                                                       \n",
       "6      Is this the worst Scottish accent ever? Englis...\n",
       "7      Sandy aftermath: Shocking photos show desperat...\n",
       "8      BBC pays staff to get up early: Workers can cl...\n",
       "9                                                       \n",
       "10                                                      \n",
       "11     Robin Williams' ashes scattered in San Francis...\n",
       "12     Bangkok subways at risk as flooodwaters inch c...\n",
       "13     Mississippi judge Bill Weisenberger indicted f...\n",
       "14                                                      \n",
       "15     Bletchley Park codebreaker dies aged 93: Last ...\n",
       "16     Hotpoint and Indesit dishwashers recalled over...\n",
       "17                                                      \n",
       "18     Martin Collett: Former David Blunkett aide kil...\n",
       "19                  China: World's workshop on the wane?\n",
       "20     Rare letter from Teddy Roosevelt to son 'Quent...\n",
       "21         Rare Hong Kong dim sum classics make comeback\n",
       "22                                                      \n",
       "23     Rangers striker Kenny Miller turns up the pres...\n",
       "24     Russia, Ukraine agree on naval-base-for-gas deal \n",
       "25          U.S. reveals secret plans for '60s moon base\n",
       "26     Report: British police made mistakes in Savile...\n",
       "27     Harry Styles shares Twitter message of support...\n",
       "28     Cyber Monday sales boosted by tablets and smar...\n",
       "29                                Stop the war on comedy\n",
       "                             ...                        \n",
       "620    Porn addict who murdered mother-in-law in sex ...\n",
       "621    Can you tell the difference? Gran Turismo 6's ...\n",
       "622    Keep your wider seats -- what planes need are ...\n",
       "623         Arctic drilling opponents win round in court\n",
       "624    Michigan teen with Down syndrome gets waiver t...\n",
       "625        Afghanistan to help review U.S. war on terror\n",
       "626       Opinion: Going beyond the headlines on the NSA\n",
       "627           Michael Phelps: 'I consider myself normal'\n",
       "628    Fair Trade photos show clothing labels which r...\n",
       "629    Kimi Raikkonen '100 per cent sure' rejoining F...\n",
       "630    Defense contractor settles bribery charges for...\n",
       "631    'Foreign Legion' in Iraq and Syria may bring j...\n",
       "632                                                     \n",
       "633                                                     \n",
       "634    African golden cat captured on video in the wi...\n",
       "635    Miami cops use photos of black teens for shoot...\n",
       "636    Ravel Morrison's garish new boots steal the sh...\n",
       "637    Canadian tourist to pay £63k after killing wom...\n",
       "638                                                     \n",
       "639    Ever wondered what's REALLY in your scampi? Yo...\n",
       "640    Moral uncertainty means machines will never kn...\n",
       "641    Pentagon to deploy 400 US troops to train Syri...\n",
       "642        Stars gather for 'We Are the World' recording\n",
       "643           Meet the U.S. 'Top Guns' with eyes on Iran\n",
       "644    Teacher Matthew Shadbolt who beat up ex-girlfr...\n",
       "645    Serbia gay pride march attacked with bombs, st...\n",
       "646    At least 13 dead in suicide attack on military...\n",
       "647    Chavez supporters take loyalty oath as preside...\n",
       "648    Torrington football rape: THIRD student charge...\n",
       "649    Washington paid for a camel's visit to Mount V...\n",
       "Name: headline, Length: 650, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean headlines\n",
    "# df['headline'] = df['headline_cleaned'] = \n",
    "# [re.sub(' - CNN.com', '', head) for head in df.loc[:, 'headline']]\n",
    "\n",
    "# df.headline.re.sub(' - CNN.com', '')\n",
    "# re.sub(' - CNN.com', '', head)\n",
    "\n",
    "# headline_cleaned = []\n",
    "# for head in df.loc[:5, 'headline']:\n",
    "#     tmp_head = re.sub(' - CNN.com |\\| Daily Mail Online', '', head)\n",
    "#     print(tmp_head)\n",
    "#     tmp_head = re.sub(' | Daily Mail Online','', tmp_head)\n",
    "#     headline_cleaned.append(tmp_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T15:51:30.818836Z",
     "start_time": "2019-02-05T15:51:30.122676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate how many lines in summaries\n",
    "len_summary = [len(summary) for summary in df.loc[:, 'summary']]\n",
    "len_story = [len(sent_tokenize(story)) for story in df.loc[:, 'story']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T15:51:39.339127Z",
     "start_time": "2019-02-05T15:51:39.334372Z"
    }
   },
   "outputs": [],
   "source": [
    "# Length of summaries, stories\n",
    "summary_descriptives = stats.describe(len_summary)\n",
    "story_descriptives = stats.describe(len_story)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate summaries using textrank with different returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T15:59:19.592682Z",
     "start_time": "2019-02-05T15:59:19.589869Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.summarization.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'story']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T04:29:25.712457Z",
     "start_time": "2019-02-05T04:29:24.974329Z"
    }
   },
   "outputs": [],
   "source": [
    "# nltk.download('wordnet')\n",
    "from gensim.utils import smart_open, simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# !pip install pyLDAvis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, nltk, spacy, gensim\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "from gensim.sklearn_api import TfIdfTransformer\n",
    "# Sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "wnl = WordNetLemmatizer()\n",
    "def tokenize(text, publishers = ['cnn', 'dailymail']):    \n",
    "    clean_text = [wnl.lemmatize(token) for token in simple_preprocess(text) if token not in (STOPWORDS or publishers) and len(token) > 3]        \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T04:30:18.481719Z",
     "start_time": "2019-02-05T04:29:53.395019Z"
    }
   },
   "outputs": [],
   "source": [
    "data_words = [' '.join(tokenize(data)) for data in df.loc[:, 'story']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T04:30:27.708868Z",
     "start_time": "2019-02-05T04:30:25.339597Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(lowercase=False)\n",
    "\n",
    "data_vectorized = vectorizer.fit_transform(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T13:41:09.015105Z",
     "start_time": "2019-02-05T04:31:20.459Z"
    }
   },
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_topics=20,               # Number of topics\n",
    "                                      max_iter=10,               # Max learning iterations\n",
    "                                      learning_method='online',   \n",
    "                                      random_state= 0,          # Random state\n",
    "#                                       batch_size=128,            # n docs in each learning iter\n",
    "                                      evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
    "                                      n_jobs = -1               # Use all available CPUs\n",
    "                                     )\n",
    "lda_output = lda_model.fit_transform(data_vectorized)\n",
    "\n",
    "print(lda_model)  # Model attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
